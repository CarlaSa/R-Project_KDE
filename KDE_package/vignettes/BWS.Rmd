---
title: "Bandwidth Selection Methods"
author: "Charlotte Boys, Leon Patzig, Carla Sagebiel"
description: >
  Learn how to use our package to select a bandwidth for Kernel Density Estimation.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bandwidth Selection Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 4
)
```

```{r, include=FALSE}
devtools::load_all(".")
library(ggplot2)
library(utils)
```

```{r setup}
library(KDE)
```

Kernel Density Estimation (KDE) is a statistical tool to estimate the underlying probability density function given a finite set of data points. As parameters, the method takes a choice kernel and a bandwidth \code{h}. Both parameters affect the 'shape' of the final estimate, but the bandwidth has the greatest influence and a selection of methods have been developed to make the best choice of bandwidth given a dataset and a chosen kernel. 

Our package provides implementations of three such bandwidth selection methods:

* Cross validation
* Goldenschluger-Lepski
* Penalized Comparison to Overfitting (PCO)

The package also provides:

* a rejection sampling algorithm to generate simulated data from a range of provided functions, with the option to input a user-generated function
* a range of KDE kernels
* an implementation of the Kernel Density Estimator given data, bandwidth and kernel

Users are also invited to explore the package through the KDE Shiny application.

## Basic usage

### Generate a dataset with `rejection_sample()`
The user is able to provide their own data, or use `rejection_sample()` to simulate sampling from a given distribution.
`rejection_sample()` has the following essential arguments:

* The first argument, `n_obs`, should be an integer giving the number of data points which should be generated.
* The second argument, `f`, is a probability density function. Users can provide their own function, or make use of one of the provided `pdf` functions:
  + `pdfs$Cauchy`
  + `pdfs$Uniform`
  + `pdfs$Expo`
  + `pdfs$Mix2Gauss`

Further arguments are optional:

* `helper`: a helper function for the rejection sampling algorithm. Choose from `helpers$normal` (default) or `helpers$uniform`.
* `n_iter`: a calibration constant (default `10`). The algorithm will take an average of `n_iter` iterations to obtain a sample.

For example, we simulate 500 data points from a Cauchy distribution with location parameter `x0 = 0` and scale parameter `gamma = 0.3`:

```{r}
pdf <- pdfs$Cauchy
data <- rejection_sample(1000, pdf)
```

### Find optimal bandwidth with `bandwidth_selection()`
`bandwidth_selection()` uses a chosen bandwidth selection method to find `h_opt`, an optimal bandwidth for use in Kernel Density Estimation. It takes the following arguments which are independent of method choice:

 * The first argument, `method` is a string naming one of three bandwidth selection methods:
    + `'CV'` for Cross-validation
    + `'PCO'` for Penalized Comparison to Overfitting
    + `'GL'` for Goldenschluger-Lepski
 * For the second argument, a `Kernel` should be chosen from the following list:
    + `kernels$gaussian`
    + `kernels$rectangular`
    + `kernels$triangular`
    + `kernels$epanechnikov` or alternatively `kernel$parabolic`
    + `kernels$biweight`
    + `kernels$silverman`
    
    
```{r, echo=FALSE}
ggplot(data.frame(x=c(-3, 3)), aes(x=x)) + 
    geom_path(aes(colour="red"), stat="function", fun=kernels$gaussian)+
    geom_path(aes(colour="blue"), stat="function", fun=kernels$rectangular) +
    geom_path(aes(colour="green"), stat="function", fun=kernels$triangular) +
    geom_path(aes(colour="yellow"), stat="function", fun=kernels$epanechnikov) +
    geom_path(aes(colour="orange"), stat="function", fun=kernels$biweight) +
    geom_path(aes(colour="black"), stat="function", fun=kernels$silverman) +
    scale_colour_identity("Function", guide="legend", 
                          labels = c("Gaussian", "Rectangular", "Triangular", "Epanechnikov", "Biweight", "Silverman"),
                          breaks = c("red", "blue", "green", "yellow", "orange", "black")) 
```

  * `data` is the dataset generated with `rejection_sample()` or otherwise
  * `maxEval` is the maximum number of function evaluations which `cubature::cubintegrate` will use to find an integral (default `maxEval = 1e3`). Particularly for the integral-heavy Goldenschluger-Lepski method, smaller values are recommended to reduce computation time. Note, however, that some kernel choices (e.g. `kernels$triangular`) require a value of `1e3` or greater for stable results.
  * `lower` (default `lower = 1e-3`) is a double value which gives the lower bound for the bandwidth search interval i.e. the smallest possible bandwidth
  * Similarly, `upper` (default `upper = 1e0`) is a double value giving an upper bound for the bandwidth search interval
  
  Further method-dependent parameters for the PCO and Goldenschluger-Lepski methods are optional:
  
#### PCO

  * A calibration constant `v` for the variance term (default `v = 1`) 

#### Goldenschluger-Lepski
  
  * A vector of `bandwidths` to test. Default `bandwidths = NULL`. 
  * If `bandwidths = NULL`, a uniform sequence of bandwidths is generated within the range between `lower` and `upper`. Parameter `n_bandwidths` (default `n_bandwidths = 20`) gives the number of bandwidths in this sequence.
  * A calibration constant `c` for the the bias term (default `c = 1`)
  * A calibration constant `v` for the variance term (default `v = 2`)
  
  For the above calibration constants, it is recommended to use a ratio `v = 2c`. A minimum admissible value of `c = 1` is recommended, although this value has only been proven asymptotically (Lacour, C. and Massart, P., 2016. Minimal penalty for goldenshlugerâ€“lepski method).

We demonstrate using the Gaussian kernel and PCO bandwidth selection method:

```{r}
kernel <- kernels$gaussian
system.time(
  h_opt <- bandwidth_selection('PCO', kernel, data, maxEval = 1e3)
  )
h_opt
```
### Get the estimator for a fixed value of h with `get_kde()`

Once we have our value of h_opt, as well as a chosen kernel and a dataset, we can find our Kernel Density Estimator using the function `get_kde()`. The arguments are as follows:

* `h`, the desired bandwidth
* `Kernel`, the same kernel used in `bandwidth_selection()`
* `data`, the same data used in `bandwidth_selection()`

We demonstrate, and plot the KDE alongside our original function:
```{r}
KDE <- get_kde(h_opt, kernel, data)
```


```{r, echo=FALSE}
ggplot(data.frame(x=c(-3, 3)), aes(x=x)) + 
    geom_path(aes(colour="red"), stat="function", fun=KDE)+
    geom_path(aes(colour="black"), stat="function", fun=pdf) +
    scale_colour_identity("Function", guide="legend", 
                          labels = c("KDE", "True pdf"),
                          breaks = c("red", "black")) 
```

## Advanced Options

### Use parallel `sapply()` with `setup_cluster()`

A weakness of our package is the heavy use of `sapply()`. To speed up the processing time, we have written a parallelised version `p_sapply()`. To make use of `p_sapply()`, we provide the user function `setup_cluster()`.
This function is called once to enable parallelization during the runtime, and will create a single cluster object for parallel computing in the global environment.
The arguments are as follows:

* `n_cores`: The user can specify the number of cores to be used in parallel. A default value is set to the total number of cores minus one. 
* `use_parallel`: set to `True` to enable parallel processing. Call the function again with `False` to disable. Default `True`.
* `overwrite`: If overwrite is left at the default value, a warning will be thrown if the cluster object already exists. If set to `True`, no warning will be shown in this case. If set to `False`, then the function gives an error if a cluster object already exists.
* `type`: a parameter passed to the parallel package. Operating system specific. See `parallel::makeCluster` for details.

To enable parallelization, call:

```{r eval=FALSE}
setup_cluster(use_parallel = TRUE)
```

To disable  parallelization, call:

```{r eval=FALSE}
setup_cluster(use_parallel = FALSE)
```
